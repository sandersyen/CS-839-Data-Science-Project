{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "from ngramGenerator import *\n",
    "from featureIdentifier import *\n",
    "from decisionTree import *\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "# Validation libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    new_train = [ngram[4:] for ngram in train_ngram_result[0]]\\n    label = [1 if ngram[0] in labels_set else 0 for ngram in train_ngram_result[0]]\\n    tree = build_decision_tree(new_train, label)\\n    print sum([1 if a == b else 0 for a, b in zip(tree.predict(new_train), label)])\\n    print len(label)\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    articles, labels_set = [], set()\n",
    "\n",
    "    ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    ''' Pre-processing                                                   '''\n",
    "    ''' (1) Load data and split data into train/test sets                '''\n",
    "    ''' (2) Hashset the labels and remove labels on the data             '''\n",
    "    ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    # add all files' data into articles\n",
    "    preprocessing.read_data(articles)\n",
    "\n",
    "    # split data to train and test sets\n",
    "    train_set, test_set = preprocessing.data_split(articles)\n",
    "    train_label_count, test_label_count = 0, 0\n",
    "\n",
    "    # take off label and add names to labels\n",
    "    for i in range(len(train_set)):\n",
    "        train_set[i], train_label_count, labels_set =\\\n",
    "            preprocessing.label_extraction_takeoff(paragraphs=train_set[i], count=train_label_count, labels=labels_set)\n",
    "\n",
    "    for i in range(len(test_set)):\n",
    "        test_set[i], test_label_count, _ =\\\n",
    "            preprocessing.label_extraction_takeoff(paragraphs=test_set[i], count=test_label_count)\n",
    "\n",
    "    ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    ''' N-gram generation                                                '''\n",
    "    ''' (1) Generate all n-gram (with first feature whether contains 's) '''\n",
    "    ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    train_ngram_result, test_ngram_result = [], []\n",
    "    train_single_gram, test_single_gram = [], []        # save single ones in order for later use\n",
    "\n",
    "    for i in range(len(train_set)):\n",
    "        ngrams, singles = generate_ngrams(filename=train_set[i][0], content=train_set[i][1], n=5)\n",
    "        train_ngram_result.append(ngrams)\n",
    "        train_single_gram.append(singles)\n",
    "\n",
    "    for i in range(len(test_set)):\n",
    "        ngrams, singles = generate_ngrams(filename=test_set[i][0], content=test_set[i][1], n=5)\n",
    "        test_ngram_result.append(ngrams)\n",
    "        test_single_gram.append(singles)\n",
    "\n",
    "    ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    ''' Take out n-gram with only lowercase (only for training data)     '''\n",
    "    ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    for index in range(len(train_ngram_result)):\n",
    "        train_ngram_result[index] = eliminateAllLower(train_ngram_result[index])\n",
    "\n",
    "    ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    ''' Feature creation                                                 '''\n",
    "    ''' (1) 's (added during generation of ngram)                        '''\n",
    "    ''' (2) country                                                      '''\n",
    "    ''' (3) conjunction                                                  '''\n",
    "    ''' (4) all capitalised                                              '''\n",
    "    ''' (5) prefix                                                       '''\n",
    "    ''' (6) verbs for humans                                             '''\n",
    "    ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    country_set, conjunction_set, prefix_set, verb_set =\\\n",
    "        loadCountryFile(), loadConjunctionFile(), loadPrefixLibrary(), loadVerbFile()\n",
    "\n",
    "    for ngram_set_index in range(len(train_ngram_result)):\n",
    "        for ngram_index in range(len(train_ngram_result[ngram_set_index])):\n",
    "            ngram = train_ngram_result[ngram_set_index][ngram_index]\n",
    "\n",
    "            train_ngram_result[ngram_set_index][ngram_index] = ngram +\\\n",
    "                (containsCountry(ngram=ngram, country_set=country_set),\n",
    "                 containsConjunction(ngram=ngram, conjunctions_set=conjunction_set),\n",
    "                 isAllUpper(ngram=ngram),\n",
    "                 hasPrefix(ngram=ngram, single_grams=train_single_gram[ngram_set_index], prefix_set=prefix_set),\n",
    "                 hasHumanVerb(ngram=ngram, single_grams=train_single_gram[ngram_set_index], verb_set=verb_set),)\n",
    "\n",
    "# below are modified by Joy. Feel free to update if there exists typos\n",
    "            \n",
    "    for ngram_set_index in range(len(test_ngram_result)):\n",
    "        for ngram_index in range(len(test_ngram_result[ngram_set_index])):\n",
    "            ngram = test_ngram_result[ngram_set_index][ngram_index]\n",
    "\n",
    "            test_ngram_result[ngram_set_index][ngram_index] = ngram +\\\n",
    "                (containsCountry(ngram=ngram, country_set=country_set),\n",
    "                 containsConjunction(ngram=ngram, conjunctions_set=conjunction_set),\n",
    "                 isAllUpper(ngram=ngram),\n",
    "                 hasPrefix(ngram=ngram, single_grams=test_single_gram[ngram_set_index], prefix_set=prefix_set),\n",
    "                 hasHumanVerb(ngram=ngram, single_grams=test_single_gram[ngram_set_index], verb_set=verb_set),)\n",
    "\n",
    "\n",
    "    return train_ngram_result,test_ngram_result,labels_set\n",
    "\n",
    "'''\n",
    "    new_train = [ngram[4:] for ngram in train_ngram_result[0]]\n",
    "    label = [1 if ngram[0] in labels_set else 0 for ngram in train_ngram_result[0]]\n",
    "    tree = build_decision_tree(new_train, label)\n",
    "    print sum([1 if a == b else 0 for a, b in zip(tree.predict(new_train), label)])\n",
    "    print len(label)\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_ngram_result,test_ngram_result,labels_set = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.DataFrame(train_ngram_result[0],columns=['elements','file','loc_start','loc_end','end_\\'s','country','conjunction','capitalised','prefix','verb'])\n",
    "true_label=[]\n",
    "for i in range(len(df['elements'])):\n",
    "    if list(df['elements'])[i] in labels_set:\n",
    "        true_label.append(1)\n",
    "    else:\n",
    "        true_label.append(0)\n",
    "df['true_label']=true_label\n",
    "true_list = df.loc[(df['true_label']== 1),:].index.tolist()\n",
    "new_list=[]\n",
    "for i in true_list:\n",
    "    if len(df['elements'][i].split()) > 1:\n",
    "        new_list.append(i)   \n",
    "            \n",
    "for i in new_list:\n",
    "    for j in range(len(df['elements'])):\n",
    "        if (df['file'][j] != 'NULL') & (df['file'][i] != 'NULL'):\n",
    "            if (df['file'][j] == df['file'][i]) & (df['loc_start'][j] >= df['loc_start'][i]) & (df['loc_end'][j] <= df['loc_end'][i]) & ((df['loc_end'][j]-df['loc_start'][j])!=(df['loc_end'][i]-df['loc_start'][i])):\n",
    "                df.iloc[j,:] = 'NULL'\n",
    "                    \n",
    "df = df.loc[(df['file'] != 'NULL'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,len(train_ngram_result)):\n",
    "    df_temp = pd.DataFrame(train_ngram_result[i],columns=['elements','file','loc_start','loc_end','end_\\'s','country','conjunction','capitalised','prefix','verb'])\n",
    "    true_label=[]\n",
    "    for i in range(len(df_temp['elements'])):\n",
    "        if list(df_temp['elements'])[i] in labels_set:\n",
    "            true_label.append(1)\n",
    "        else:\n",
    "            true_label.append(0)\n",
    "    df_temp['true_label']=true_label\n",
    "    true_list = df_temp.loc[(df_temp['true_label']== 1),:].index.tolist()\n",
    "    new_list=[]\n",
    "    for i in true_list:\n",
    "        if len(df_temp['elements'][i].split()) > 1:\n",
    "            new_list.append(i)   \n",
    "            \n",
    "    for i in new_list:\n",
    "        for j in range(len(df_temp['elements'])):\n",
    "            if (df_temp['file'][j] != 'NULL') & (df_temp['file'][i] != 'NULL'):\n",
    "                if (df_temp['file'][j] == df_temp['file'][i]) & (df_temp['loc_start'][j] >= df_temp['loc_start'][i]) & (df_temp['loc_end'][j] <= df_temp['loc_end'][i]) & ((df_temp['loc_end'][j]-df_temp['loc_start'][j])!=(df_temp['loc_end'][i]-df_temp['loc_start'][i])):\n",
    "                    df_temp.iloc[j,:] = 'NULL'\n",
    "                    \n",
    "    df_append = df_temp.loc[(df_temp['file'] != 'NULL'),:]\n",
    "    df = df.append(df_append, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DataFrame.to_csv(df,\"final_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('final_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elements</th>\n",
       "      <th>file</th>\n",
       "      <th>loc_start</th>\n",
       "      <th>loc_end</th>\n",
       "      <th>end_'s</th>\n",
       "      <th>country</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>prefix</th>\n",
       "      <th>verb</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Mathison Turing</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK During</td>\n",
       "      <td>289</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Second World</td>\n",
       "      <td>289</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Second World War</td>\n",
       "      <td>289</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Second World War Turing</td>\n",
       "      <td>289</td>\n",
       "      <td>94</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>World War</td>\n",
       "      <td>289</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>World War Turing</td>\n",
       "      <td>289</td>\n",
       "      <td>95</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>War Turing</td>\n",
       "      <td>289</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Government Code</td>\n",
       "      <td>289</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cypher School</td>\n",
       "      <td>289</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cypher School GC&amp;CS</td>\n",
       "      <td>289</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>School GC&amp;CS</td>\n",
       "      <td>289</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bletchley Park</td>\n",
       "      <td>289</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bletchley Park Britain</td>\n",
       "      <td>289</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Park Britain</td>\n",
       "      <td>289</td>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hut 8</td>\n",
       "      <td>289</td>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>National Physical</td>\n",
       "      <td>289</td>\n",
       "      <td>255</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>National Physical Laboratory</td>\n",
       "      <td>289</td>\n",
       "      <td>255</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Physical Laboratory</td>\n",
       "      <td>289</td>\n",
       "      <td>256</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In 1948</td>\n",
       "      <td>289</td>\n",
       "      <td>271</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>In 1948 Turing</td>\n",
       "      <td>289</td>\n",
       "      <td>271</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1948 Turing</td>\n",
       "      <td>289</td>\n",
       "      <td>272</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Max Newman</td>\n",
       "      <td>289</td>\n",
       "      <td>275</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Max Newman Computing</td>\n",
       "      <td>289</td>\n",
       "      <td>275</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Max Newman Computing Machine</td>\n",
       "      <td>289</td>\n",
       "      <td>275</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Max Newman Computing Machine Laboratory</td>\n",
       "      <td>289</td>\n",
       "      <td>275</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Newman Computing</td>\n",
       "      <td>289</td>\n",
       "      <td>276</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Newman Computing Machine</td>\n",
       "      <td>289</td>\n",
       "      <td>276</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Newman Computing Machine Laboratory</td>\n",
       "      <td>289</td>\n",
       "      <td>276</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Computing Machine</td>\n",
       "      <td>289</td>\n",
       "      <td>277</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10899</th>\n",
       "      <td>Copernicanae</td>\n",
       "      <td>290</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>These</td>\n",
       "      <td>290</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10901</th>\n",
       "      <td>Newton</td>\n",
       "      <td>290</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>Kepler</td>\n",
       "      <td>290</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>Graz</td>\n",
       "      <td>290</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10904</th>\n",
       "      <td>Prince</td>\n",
       "      <td>290</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10905</th>\n",
       "      <td>Eggenberg</td>\n",
       "      <td>290</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10906</th>\n",
       "      <td>Later</td>\n",
       "      <td>290</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10907</th>\n",
       "      <td>Prague</td>\n",
       "      <td>290</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10908</th>\n",
       "      <td>Emperor</td>\n",
       "      <td>290</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10909</th>\n",
       "      <td>Matthias</td>\n",
       "      <td>290</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10910</th>\n",
       "      <td>He</td>\n",
       "      <td>290</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10911</th>\n",
       "      <td>Linz</td>\n",
       "      <td>290</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>General</td>\n",
       "      <td>290</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>Wallenstein</td>\n",
       "      <td>290</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10914</th>\n",
       "      <td>Additionally</td>\n",
       "      <td>290</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10915</th>\n",
       "      <td>Keplerian</td>\n",
       "      <td>290</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10916</th>\n",
       "      <td>He</td>\n",
       "      <td>290</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10917</th>\n",
       "      <td>Accademia</td>\n",
       "      <td>290</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10918</th>\n",
       "      <td>Lincei</td>\n",
       "      <td>290</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10919</th>\n",
       "      <td>Rome[4]</td>\n",
       "      <td>290</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10920</th>\n",
       "      <td>Kepler</td>\n",
       "      <td>290</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10921</th>\n",
       "      <td>Kepler</td>\n",
       "      <td>290</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10922</th>\n",
       "      <td>God</td>\n",
       "      <td>290</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10923</th>\n",
       "      <td>Kepler</td>\n",
       "      <td>290</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10924</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>290</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10925</th>\n",
       "      <td>Metaphysics[7]</td>\n",
       "      <td>290</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10926</th>\n",
       "      <td>Aristotle</td>\n",
       "      <td>290</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10927</th>\n",
       "      <td>On</td>\n",
       "      <td>290</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10928</th>\n",
       "      <td>Heavens[8]</td>\n",
       "      <td>290</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10929 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      elements  file  loc_start  loc_end  \\\n",
       "0                         Alan Mathison Turing   289          0        2   \n",
       "1                                    UK During   289         91       92   \n",
       "2                                 Second World   289         94       95   \n",
       "3                             Second World War   289         94       96   \n",
       "4                      Second World War Turing   289         94       97   \n",
       "5                                    World War   289         95       96   \n",
       "6                             World War Turing   289         95       97   \n",
       "7                                   War Turing   289         96       97   \n",
       "8                              Government Code   289        101      102   \n",
       "9                                Cypher School   289        104      105   \n",
       "10                         Cypher School GC&CS   289        104      106   \n",
       "11                                School GC&CS   289        105      106   \n",
       "12                              Bletchley Park   289        108      109   \n",
       "13                      Bletchley Park Britain   289        108      110   \n",
       "14                                Park Britain   289        109      110   \n",
       "15                                       Hut 8   289        122      123   \n",
       "16                           National Physical   289        255      256   \n",
       "17                National Physical Laboratory   289        255      257   \n",
       "18                         Physical Laboratory   289        256      257   \n",
       "19                                     In 1948   289        271      272   \n",
       "20                              In 1948 Turing   289        271      273   \n",
       "21                                 1948 Turing   289        272      273   \n",
       "22                                  Max Newman   289        275      276   \n",
       "23                        Max Newman Computing   289        275      277   \n",
       "24                Max Newman Computing Machine   289        275      278   \n",
       "25     Max Newman Computing Machine Laboratory   289        275      279   \n",
       "26                            Newman Computing   289        276      277   \n",
       "27                    Newman Computing Machine   289        276      278   \n",
       "28         Newman Computing Machine Laboratory   289        276      279   \n",
       "29                           Computing Machine   289        277      278   \n",
       "...                                        ...   ...        ...      ...   \n",
       "10899                             Copernicanae   290         37       37   \n",
       "10900                                    These   290         38       38   \n",
       "10901                                   Newton   290         47       47   \n",
       "10902                                   Kepler   290         52       52   \n",
       "10903                                     Graz   290         62       62   \n",
       "10904                                   Prince   290         69       69   \n",
       "10905                                Eggenberg   290         73       73   \n",
       "10906                                    Later   290         74       74   \n",
       "10907                                   Prague   290         85       85   \n",
       "10908                                  Emperor   290         92       92   \n",
       "10909                                 Matthias   290         99       99   \n",
       "10910                                       He   290        103      103   \n",
       "10911                                     Linz   290        108      108   \n",
       "10912                                  General   290        114      114   \n",
       "10913                              Wallenstein   290        115      115   \n",
       "10914                             Additionally   290        116      116   \n",
       "10915                                Keplerian   290        135      135   \n",
       "10916                                       He   290        149      149   \n",
       "10917                                Accademia   290        156      156   \n",
       "10918                                   Lincei   290        158      158   \n",
       "10919                                  Rome[4]   290        160      160   \n",
       "10920                                   Kepler   290        161      161   \n",
       "10921                                   Kepler   290        199      199   \n",
       "10922                                      God   290        217      217   \n",
       "10923                                   Kepler   290        236      236   \n",
       "10924                                Aristotle   290        248      248   \n",
       "10925                           Metaphysics[7]   290        249      249   \n",
       "10926                                Aristotle   290        255      255   \n",
       "10927                                       On   290        256      256   \n",
       "10928                               Heavens[8]   290        258      258   \n",
       "\n",
       "       end_'s  country  conjunction  prefix  verb  true_label  \n",
       "0           0        0            0       0     1           1  \n",
       "1           0        1            0       0     0           0  \n",
       "2           0        0            0       0     0           0  \n",
       "3           0        0            0       0     0           0  \n",
       "4           0        0            0       0     1           0  \n",
       "5           0        0            0       0     0           0  \n",
       "6           0        0            0       0     1           0  \n",
       "7           0        0            0       0     1           0  \n",
       "8           0        0            0       0     0           0  \n",
       "9           0        0            0       0     0           0  \n",
       "10          0        0            0       0     0           0  \n",
       "11          0        0            0       0     0           0  \n",
       "12          0        0            0       0     0           0  \n",
       "13          1        0            0       0     0           0  \n",
       "14          1        0            0       0     0           0  \n",
       "15          0        0            0       0     0           0  \n",
       "16          0        0            0       0     0           0  \n",
       "17          0        0            0       0     0           0  \n",
       "18          0        0            0       0     0           0  \n",
       "19          0        0            0       0     0           0  \n",
       "20          0        0            0       0     1           0  \n",
       "21          0        0            0       0     1           0  \n",
       "22          1        0            0       0     0           0  \n",
       "23          0        0            0       0     0           0  \n",
       "24          0        0            0       0     0           0  \n",
       "25          0        0            0       0     0           0  \n",
       "26          0        0            0       0     0           0  \n",
       "27          0        0            0       0     0           0  \n",
       "28          0        0            0       0     0           0  \n",
       "29          0        0            0       0     0           0  \n",
       "...       ...      ...          ...     ...   ...         ...  \n",
       "10899       0        0            0       0     0           0  \n",
       "10900       0        0            0       0     0           0  \n",
       "10901       1        0            0       0     0           1  \n",
       "10902       0        0            0       0     1           1  \n",
       "10903       0        0            0       0     0           0  \n",
       "10904       0        0            0       0     0           0  \n",
       "10905       0        0            0       0     0           0  \n",
       "10906       0        0            0       0     0           0  \n",
       "10907       0        0            0       0     0           0  \n",
       "10908       0        0            0       0     0           0  \n",
       "10909       0        0            0       0     0           1  \n",
       "10910       0        0            0       0     0           0  \n",
       "10911       0        0            0       0     0           0  \n",
       "10912       0        0            0       0     0           0  \n",
       "10913       0        0            0       1     0           1  \n",
       "10914       0        0            0       0     0           0  \n",
       "10915       0        0            0       0     0           0  \n",
       "10916       0        0            0       0     1           0  \n",
       "10917       0        0            0       0     0           0  \n",
       "10918       0        0            0       0     0           0  \n",
       "10919       0        0            0       0     0           0  \n",
       "10920       0        0            0       0     1           1  \n",
       "10921       0        0            0       0     0           1  \n",
       "10922       0        0            0       0     1           0  \n",
       "10923       0        0            0       0     1           1  \n",
       "10924       1        0            0       0     0           1  \n",
       "10925       0        0            0       0     0           0  \n",
       "10926       1        0            0       0     0           1  \n",
       "10927       0        0            0       0     0           0  \n",
       "10928       0        0            0       0     0           0  \n",
       "\n",
       "[10929 rows x 10 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['country'], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=df.iloc[:,4:8].values.astype('int')\n",
    "y=df.iloc[:,8].values.astype('int')\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, \n",
    "                     stratify=y,\n",
    "                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodDict = {}\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 88.84%\n",
      "Best Params: {'n_estimators': 6}\n",
      "Test Accuracy: 88.29%\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     RandomForestClassifier())\n",
    "\n",
    "param_grid = {'n_estimators': list(range(1, 50))}\n",
    "\n",
    "gs = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                  param_grid=param_grid, \n",
    "                  iid=False,\n",
    "                  n_jobs=-1,\n",
    "                  refit=True,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Accuracy: %.2f%%' % (gs.best_score_*100))\n",
    "print('Best Params: %s' % gs.best_params_)\n",
    "print('Test Accuracy: %.2f%%' % (gs.best_estimator_.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RandomForest=RandomForestClassifier(n_estimators=6,n_jobs=-1,criterion='gini',\n",
    "                     random_state=0)\n",
    "RandomForest.fit(X_train, y_train)\n",
    "y_predict=RandomForest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1921,   11],\n",
       "       [ 245,    9]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def confusion_matrix(y_true, y_predicted):\n",
    "\n",
    "    unique_labels = np.unique(np.concatenate((y_true, y_predicted)))\n",
    "    num_labels=len(unique_labels)\n",
    "    matrix = np.zeros(num_labels*num_labels).reshape(num_labels, num_labels).astype(int)\n",
    "    for i, j in zip(y_true, y_predicted):\n",
    "        matrix[i,j]+=1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "result_matrix = confusion_matrix(y_test, y_predict)\n",
    "result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from helper import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(result_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `SVC()` not found.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "?SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear', gamma=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyzhu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 88.84%\n",
      "Best Params: {'C': 0.12}\n",
      "Test Accuracy: 88.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     svm.SVC())\n",
    "\n",
    "param_grid = {'C': list(np.arange(0.1,1,0.01))}\n",
    "\n",
    "gs = GridSearchCV(estimator= svm.SVC() , \n",
    "                  param_grid=param_grid, \n",
    "                  iid=False,\n",
    "                  n_jobs=-1,\n",
    "                  refit=True,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Accuracy: %.2f%%' % (gs.best_score_*100))\n",
    "print('Best Params: %s' % gs.best_params_)\n",
    "print('Test Accuracy: %.2f%%' % (gs.best_estimator_.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyzhu/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svm=svm.SVC(C=0.12)\n",
    "svm.fit(X_train, y_train)\n",
    "y_predict=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1921,   11],\n",
       "       [ 245,    9]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_matrix = confusion_matrix(y_test, y_predict)\n",
    "result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
